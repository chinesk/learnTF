#### 2020.3.21å‘¨å…­
&emsp;1.ä»Šå¤©åœ¨å®¶ï¼Œç™¾æ— èŠèµ–ï¼Œä¸Šåˆçœ‹äº†ä¸€ä¼šå„¿**å¼ çˆ±ç²**çš„**ã€Šä¼ å¥‡ã€‹**ã€‚
&emsp;2.ä¸­åˆåƒæ–¹ä¾¿é¢ï¼Œçœ‹äº†**ã€Šç™¾ä¸‡æ€äººæ¸¸æˆã€‹**ã€‚
&emsp;3.ä¸‹åˆåˆä¼‘èµ·æ¥ï¼Œå¾ˆçƒ­ï¼Œè¯•äº†ä¸€ä¸‹**IA Writer**å’Œ**Typora**éƒ½ç”¨ä¸æƒ¯ï¼Œæœ€åç”¨**ç½‘é¡µç‰ˆé©¬å…‹é£è±¡**å†™äº†ä¸€ç¯‡æ—¥è®°ï¼Œä¸çŸ¥é“æ”¶è´¹ä¸ã€‚
&emsp;4.ä»Šå¤©å¤–å©†å’Œç‹å®¶ä¸€å®¶äººå‡ºå»è€ï¼Œé‚£è¾¹ä¸¤ä¸ªå°çš„éƒ½å»äº†ï¼Œæ²¡æœ‰å–Šå¤©å¤©ï¼Œåæ­£æˆ‘å¾ˆä¸å–œæ¬¢ï¼Œä¹Ÿä¸åœ¨ä¹å¤šä¸€ç‚¹è®¨åŒã€‚
<center>**å±…ä¸­è¿˜æ˜¯å¯ä»¥çš„**<center>
<center>[å…‰çº¤æ”¶å‘å™¨å’Œå…‰æ¨¡å—](https://www.diangon.com/m436921.html)<center>
<center>![@å…‰çº¤æ”¶å‘å™¨](./084502fxo3m69sqlzlv0od.jpg)<center>



## ğŸ†• Are you looking for a new YOLOv3 implemented by TF2.0 ?

>If you hate the fucking tensorflow1.x very much, no worries! I have implemented **a new YOLOv3 repo with TF2.0**, and also made a chinese blog on how to implement YOLOv3 object detector from scratch. <br>
[code](https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3) | [blog](https://yunyang1994.github.io/posts/YOLOv3/#more)  | [issue](https://github.com/YunYang1994/tensorflow-yolov3/issues/39)

## part 1. Quick start
1. Clone this file
```bashrc
$ git clone https://github.com/YunYang1994/tensorflow-yolov3.git
```
2.  You are supposed  to install some dependencies before getting out hands with these codes.
```bashrc
$ cd tensorflow-yolov3
$ pip install -r ./docs/requirements.txt
```
3. Exporting loaded COCO weights as TF checkpoint(`yolov3_coco.ckpt`)ã€[BaiduCloud](https://pan.baidu.com/s/11mwiUy8KotjUVQXqkGGPFQ&shfl=sharepset) ã€‘
```bashrc
$ cd checkpoint
$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz
$ tar -xvf yolov3_coco.tar.gz
$ cd ..
$ python convert_weight.py
$ python freeze_graph.py
```
4. Then you will get some `.pb` files in the root path.,  and run the demo script
```bashrc
$ python image_demo.py
$ python video_demo.py # if use camera, set video_path = 0
```
<p align="center">
    <img width="100%" src="https://user-images.githubusercontent.com/30433053/68088581-9255e700-fe9b-11e9-8672-2672ab398abe.jpg" style="max-width:100%;">
    </a>
</p>

## part 2. Train your own dataset
Two files are required as follows:

-  [`dataset.txt`](https://raw.githubusercontent.com/YunYang1994/tensorflow-yolov3/master/data/dataset/voc_train.txt): 

```
xxx/xxx.jpg 18.19,6.32,424.13,421.83,20 323.86,2.65,640.0,421.94,20 
xxx/xxx.jpg 48,240,195,371,11 8,12,352,498,14
# image_path x_min, y_min, x_max, y_max, class_id  x_min, y_min ,..., class_id 
# make sure that x_max < width and y_max < height
```

-  [`class.names`](https://github.com/YunYang1994/tensorflow-yolov3/blob/master/data/classes/coco.names) :

```
person
bicycle
car
...
toothbrush
```

###  2.1 Train on VOC dataset
Download VOC PASCAL trainval  and test data
```bashrc
$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar
$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
$ wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar
```
Extract all of these tars into one directory and rename them, which should have the following basic structure.

```bashrc

VOC           # path:  /home/yang/dataset/VOC
â”œâ”€â”€ test
|    â””â”€â”€VOCdevkit
|        â””â”€â”€VOC2007 (from VOCtest_06-Nov-2007.tar)
â””â”€â”€ train
     â””â”€â”€VOCdevkit
         â””â”€â”€VOC2007 (from VOCtrainval_06-Nov-2007.tar)
         â””â”€â”€VOC2012 (from VOCtrainval_11-May-2012.tar)
                     
$ python scripts/voc_annotation.py --data_path /home/yang/test/VOC
```
Then edit your `./core/config.py` to make some necessary configurations

```bashrc
__C.YOLO.CLASSES                = "./data/classes/voc.names"
__C.TRAIN.ANNOT_PATH            = "./data/dataset/voc_train.txt"
__C.TEST.ANNOT_PATH             = "./data/dataset/voc_test.txt"
```
Here are two kinds of training method: 

#####  (1) train from scratch:

```bashrc
$ python train.py
$ tensorboard --logdir ./data
```
#####  (2) train from COCO weights(recommend):

```bashrc
$ cd checkpoint
$ wget https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3_coco.tar.gz
$ tar -xvf yolov3_coco.tar.gz
$ cd ..
$ python convert_weight.py --train_from_coco
$ python train.py
```
###  2.2 Evaluate on VOC dataset

```
$ python evaluate.py
$ cd mAP
$ python main.py -na
```

the mAP on the VOC2012 dataset:

<p align="center">
    <img width="50%" src="https://user-images.githubusercontent.com/33013904/58227054-dd4fc800-7d5b-11e9-85aa-67854292fbe0.png" style="max-width:100%;">
    </a>
</p>


## part 3. Stargazers over time

[![Stargazers over time](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3.svg)](https://starcharts.herokuapp.com/YunYang1994/tensorflow-yolov3)

## part 4. Other Implementations

[-**`YOLOv3ç›®æ ‡æ£€æµ‹æœ‰äº†TensorFlowå®ç°ï¼Œå¯ç”¨è‡ªå·±çš„æ•°æ®æ¥è®­ç»ƒ`**](https://mp.weixin.qq.com/s/cq7g1-4oFTftLbmKcpi_aQ)<br>

[-**`Stronger-yolo`**](https://github.com/Stinky-Tofu/Stronger-yolo)<br>

[- **`Implementing YOLO v3 in Tensorflow (TF-Slim)`**](https://itnext.io/implementing-yolo-v3-in-tensorflow-tf-slim-c3c55ff59dbe)

[- **`YOLOv3_TensorFlow`**](https://github.com/wizyoung/YOLOv3_TensorFlow)

[- **`Object Detection using YOLOv2 on Pascal VOC2012`**](https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html)

[-**`Understanding YOLO`**](https://hackernoon.com/understanding-yolo-f5a74bbc7967)

<p align="center">
    æ±‰å­—
    </a>
</p>
<p align="center">
    <img width="100%" src="https://user-images.githubusercontent.com/30433053/68088581-9255e700-fe9b-11e9-8672-2672ab398abe.jpg" style="max-width:100%;">
    </a>
</p>




![@test image](https://user-images.githubusercontent.com/30433053/68088581-9255e700-fe9b-11e9-8672-2672ab398abe.jpg)
